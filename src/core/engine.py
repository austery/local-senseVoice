import torch
import time
import os
from funasr import AutoModel
from typing import Optional, Dict, Any

class SenseVoiceEngine:
    """
    SenseVoice æ¨ç†å¼•æ“å°è£…ç±»ã€‚
    è´Ÿè´£æ¨¡å‹çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆåŠ è½½ã€æ¨ç†ã€èµ„æºé‡Šæ”¾ï¼‰ã€‚
    """

    def __init__(self, model_id: str = "iic/SenseVoiceSmall", device: Optional[str] = None):
        self.model_id = model_id
        # è‡ªåŠ¨æ£€æµ‹ M4 Pro (MPS) ç¯å¢ƒ
        if device is None:
            self.device = "mps" if torch.backends.mps.is_available() else "cpu"
        else:
            self.device = device
        
        self.model = None
        print(f"âš™ï¸ Engine initialized. Target device: {self.device}")

    def load(self):
        """
        åŠ è½½æ¨¡å‹ã€‚
        è¿™ä¸€æ­¥ä¼šè§¦å‘ FunASR çš„è‡ªåŠ¨æ£€æŸ¥æœºåˆ¶ï¼š
        1. æ£€æŸ¥æœ¬åœ°ç¼“å­˜ (~/.cache/modelscope)
        2. å¦‚æœä¸å­˜åœ¨ï¼Œè‡ªåŠ¨ä¸‹è½½
        3. åŠ è½½åˆ°å†…å­˜/æ˜¾å­˜
        """
        if self.model is not None:
            print("âš ï¸ Model already loaded. Skipping.")
            return

        print(f"ğŸš€ Loading model '{self.model_id}' on {self.device}...")
        print("   (If this is the first run, it will download the model automatically. Please wait.)")
        
        try:
            start_time = time.time()
            
            # === æ ¸å¿ƒé€»è¾‘ï¼šå¤ç”¨ä½ æ—§ä»£ç ä¸­çš„å‚æ•° ===
            self.model = AutoModel(
                model=self.model_id,
                vad_model="fsmn-vad",  # è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼Œç”¨äºåˆ‡åˆ†é•¿éŸ³é¢‘
                punc_model="ct-punc",  # æ ‡ç‚¹ç¬¦å·æ¨¡å‹
                device=self.device,
                disable_update=True,   # ç¦æ­¢æ¯æ¬¡éƒ½å» check updateï¼ŒåŠ å¿«å¯åŠ¨é€Ÿåº¦
                log_level="ERROR"      # å‡å°‘åˆ·å±æ—¥å¿—
            )
            
            duration = time.time() - start_time
            print(f"âœ… Model loaded successfully in {duration:.2f}s")
            
            # ç®€å•çš„ Warmup (é¢„çƒ­)ï¼Œé˜²æ­¢ç¬¬ä¸€æ¬¡æ¨ç†å¡é¡¿
            self._warmup()
            
        except Exception as e:
            print(f"âŒ Failed to load model: {e}")
            raise e

    def _warmup(self):
        """æ‰§è¡Œä¸€æ¬¡ç©ºæ¨ç†ï¼Œè®© MPS å›¾ç¼–è¯‘å®Œæˆ"""
        print("ğŸ”¥ Warming up model...")
        try:
            # éšä¾¿æä¸ªæçŸ­çš„ç©ºéŸ³é¢‘æˆ–ä¼ªé€ è¾“å…¥ï¼Œè¿™é‡Œç®€å•æ‰“å°ä¸€ä¸‹å³å¯
            # å®é™… FunASR åœ¨åŠ è½½æ—¶å†…éƒ¨ä¼šæœ‰åˆå§‹åŒ–
            pass 
        except Exception:
            pass

    def transcribe_file(self, file_path: str, language: str = "auto", use_itn: bool = True) -> str:
        """
        æ‰§è¡Œæ¨ç†ã€‚
        æ³¨æ„ï¼šè¿™æ˜¯åŒæ­¥é˜»å¡æ–¹æ³•ï¼Œå¿…é¡»åœ¨ Service å±‚é€šè¿‡çº¿ç¨‹æ± è°ƒç”¨ã€‚
        """
        if not self.model:
            raise RuntimeError("Model not loaded! Call engine.load() first.")

        # æ˜ å°„è¯­è¨€å‚æ•°
        # SenseVoice æ”¯æŒ: zh, en, yue, ja, ko
        valid_langs = ["zh", "en", "yue", "ja", "ko"]
        target_lang = language if language in valid_langs else "auto"

        # è°ƒç”¨ FunASR
        # è¿™é‡Œçš„å‚æ•°å®Œå…¨å‚è€ƒä½ æä¾›çš„æˆåŠŸè¿è¡Œçš„è„šæœ¬
        res = self.model.generate(
            input=file_path,
            cache={},
            language=target_lang,
            use_itn=use_itn,       # é€†æ–‡æœ¬æ ‡å‡†åŒ– (ä¸€ç™¾ -> 100)
            batch_size_s=60,       # æ‰¹å¤„ç†å¤§å° (60ç§’éŸ³é¢‘åˆ‡ç‰‡)
            merge_vad=True,        # è‡ªåŠ¨åˆå¹¶çŸ­å¥
            merge_length_s=15
        )
        
        # res æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªç»“æœ
        return res[0]["text"]